# -*- coding: utf-8 -*-
"""Model.py_Free.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wCM-yhrewDhtTNutjWlmWgv4WFFsyQzo
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
import warnings
warnings.filterwarnings("ignore")

df=pd.read_excel("/content/Final_train_prep.xlsx")
df.head()

# Drop the columns "Sl. No.","Cheque No","Date" from the dataframe
df=df.drop(['Sl. No.','Cheque No.','Date'],axis=1)

# Creating new dataframe for analysis which does not contain any nulls in category and sub category columns 
df=df[:21362]
df_test=df[21362:]

# Importing libraries for text processing
import re
import nltk
nltk.download('stopwords')
stop_words=set(nltk.corpus.stopwords.words('english'))
nltk.download('punkt')
from nltk.tokenize import word_tokenize
df.head(5)

# Creating a function to clean the text
def clean_text(text):
  #convert words to lower case
  text=str(text).lower()

  # Remove special characters
  text=re.sub(r'[^A-Za-z0-9]+',' ',str(text).strip())

   #Tokenize
  text_list=word_tokenize(text)

  #  Remove stopwords
  text_list=[word for word in text_list if (word not in stop_words)]
  text=' '.join(text_list)
  return str(text)

# Using lambda function to apply the clean_text function to "Description" column
text_raw=df['Description']
text_b=text_raw.apply(lambda x:clean_text(x))
df['Cleaned_Description']=text_b

# Encoding the categories to labels with respect to number of transactions made in that category.

categories={'Payments':0, 'Credit':1,'Fund Transfer':2 ,'Others':3, 'Shopping':4,'Food':5,  'Investment':6,'Entertainment':7,
       'Travel':8,'Healthcare':9,'Education':10}

# Using map function to encode the 'category' column
df['Label']=df['Category'].map(categories)

from sklearn.model_selection import train_test_split
X=df['Cleaned_Description']
y=df['Label']

# Splitting the dataset into training and testing part and also we have used 'Stratify' because we haveunequal number of transaction per each category
x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,stratify=df.Label)

x_train.shape

df['Label'].value_counts()

# Feeding the train and test data to Tfidf vectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf=TfidfVectorizer()
xtrain_tf=tfidf.fit_transform(x_train)
xtest_tf=tfidf.transform(x_test)

#Importing all the necessary machine learning models for model building
from sklearn.svm import LinearSVC

#Train the model
Svm=LinearSVC(multi_class='ovr')
Svm.fit(xtrain_tf,y_train)

# Prediction by the model
def predict(x):
   pred=Svm.predict(x)
   return pred

print(predict(xtest_tf))